{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnose and Probe an Image Classifier\n",
    "\n",
    "Today we'll:\n",
    "\n",
    "- Look at the images that have the highest loss (does that necessarily mean that the classifier got them wrong?)\n",
    "- Run the output layer (the linear classifier) by hand to see how to interpret it as comparing features with prototypes for each class.\n",
    "- Compute the cross-entropy loss by hand and check if we match Keras's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check versions of Keras and Tensorflow\n",
    "!pip list | egrep 'keras|tensorflow$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Results are better with the TensorFlow backend; this is probably a bug in Keras 3 but I haven't tracked it down.\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import keras\n",
    "import keras_cv\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "print(f\"Keras version: {keras.__version__}, backend: {keras.backend.backend()}\")\n",
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "print(f\"GPUs: {num_gpus}\")\n",
    "if num_gpus == 0:\n",
    "    display(HTML(\"No GPUs available. Training will be slow. <b>Please enable an accelerator.</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_grid(images, titles=None, rows=None, cols=3, title_fontsize=8, figsize=(10, 10)):\n",
    "    if rows is None:\n",
    "        rows = (len(images) + (cols - 1)) // cols\n",
    "\n",
    "    fig, axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    for ax in axs.flatten(): ax.axis('off')\n",
    "    for i, ax in enumerate(axs.flatten()):\n",
    "        if i >= len(images): break\n",
    "        ax.imshow(np.array(images[i]).astype('uint8'))\n",
    "        if titles is not None:\n",
    "            ax.set_title(titles[i], fontsize=title_fontsize)\n",
    "\n",
    "def get_images_from_dataset(dataset, indices):\n",
    "    if hasattr(dataset, 'file_paths'):\n",
    "        # FIXME: hardcoded options\n",
    "        img_loader_opts = dict(target_size=(256, 256), keep_aspect_ratio=True)\n",
    "        items_by_idx = {idx: keras.utils.load_img(dataset.file_paths[idx], **img_loader_opts) for idx in indices}\n",
    "    else:\n",
    "        items_by_idx = {idx: item for idx, (item, label) in enumerate(dataset.unbatch()) if idx in indices}\n",
    "    return [items_by_idx[idx] for idx in indices]    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    seed = 123\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 1\n",
    "    batch_size = 16\n",
    "    image_size = (256, 256)\n",
    "    model_preset = \"efficientnetv2_b0_imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "# See https://keras.io/examples/keras_recipes/reproducibility_recipes/\n",
    "#\n",
    "# Set a seed so that the results are the same every time this is run.\n",
    "keras.utils.set_random_seed(config.seed)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a dataset of flower images for this example, but you can later switch this out for another dataset as long as you keep the file-and-folder structure.\n",
    "\n",
    "The details of the code in this section are not important at this time; just run these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_downloaded_file = keras.utils.get_file(\n",
    "    origin=\"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\",\n",
    "    extract=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what just got downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(path_to_downloaded_file).parent / 'flower_photos'\n",
    "!ls {data_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a Keras helper function to load the data.\n",
    "\n",
    "Docs: https://keras.io/api/data_loading/image/#imagedatasetfromdirectory-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which classes we want to use, in what order.\n",
    "class_names = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "\n",
    "# Create training and validation datasets\n",
    "train_dataset, val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    data_path,\n",
    "    validation_split=0.2,\n",
    "    labels='inferred',\n",
    "    class_names=class_names,\n",
    "    label_mode='int',\n",
    "    batch_size=config.batch_size,\n",
    "    image_size=config.image_size,\n",
    "    shuffle=True,\n",
    "    seed=128,\n",
    "    subset='both',\n",
    "    crop_to_aspect_ratio=True   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show some example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[example_images, example_labels]] = train_dataset.take(1)\n",
    "show_image_grid(\n",
    "    example_images,\n",
    "    titles=[f\"{label} ({class_names[label]})\" for label in example_labels])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model using a pretrained backbone\n",
    "# See https://keras.io/api/keras_cv/models/tasks/image_classifier/ for options\n",
    "model = keras_cv.models.ImageClassifier.from_preset(\n",
    "    config.model_preset,\n",
    "    num_classes=len(class_names))\n",
    "\n",
    "# Freeze the backbone\n",
    "model.backbone.trainable = False\n",
    "\n",
    "# Set up the model for training\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=config.learning_rate),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary(show_trainable=True)\n",
    "\n",
    "# Train the model. (Note: this may show some warnings, and it may stop without showing\n",
    "# progress for up to a minute while it translates the model to run on the GPU.)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=config.epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top Losses\n",
    "\n",
    "The following code will compute the model's predictions on the validation set and extract the corresponding correct labels. We'll use this to compute the loss for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "val_predicted_probs = model.predict(val_dataset)\n",
    "val_predicted_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Check**: what do the two numbers in that shape mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Get the labels from the dataset (to check whether the model got them right)\n",
    "val_labels = [int(label) for img, label in val_dataset.unbatch()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# compute loss for each sample\n",
    "loss_func = keras.losses.SparseCategoricalCrossentropy(reduction=keras.losses.Reduction.NONE)\n",
    "val_losses = loss_func(val_labels, val_predicted_probs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_top_losses(dataset, predictions, losses, labels, class_names, n=9, **kw):\n",
    "    top_n_indices = np.argsort(losses)[-n:][::-1].tolist()\n",
    "    titles = []\n",
    "    for idx in top_n_indices:\n",
    "        label = labels[idx]\n",
    "        pred = predictions[idx]\n",
    "        titles.append(f\"label={class_names[label]}\\npred={class_names[np.argmax(pred)]}\\nprob[lbl]={pred[label]:.3f}, loss={losses[idx]:.2f}\")\n",
    "    images = get_images_from_dataset(dataset, top_n_indices)\n",
    "    show_image_grid(images, titles, **kw)\n",
    "\n",
    "plot_top_losses(val_dataset, val_predicted_probs, val_losses, val_labels, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. What trend do you observe about the `loss` values shown above the images?\n",
    "2. What trend do you observe about the `pred[label]` values shown?\n",
    "3. Compute the cross-entropy loss for the bottom-right image by hand and check if it matches the `loss` value shown.\n",
    "4. Could an image show up on this grid if it was classified correctly? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Last Layer\n",
    "\n",
    "We'll now run the last layer of the model by hand to see how it compares features with prototypes for each class.\n",
    "\n",
    "The following code will compute the outputs of the feature extractor (the input to the last layer of the model) for all of the images in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "last_linear_layer = model.layers[-1]\n",
    "feature_extractor = keras.Model(inputs=model.inputs, outputs=last_linear_layer.input)\n",
    "val_features = feature_extractor.predict(val_dataset)\n",
    "val_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observe**\n",
    "\n",
    "1. What do those two numbers in the shape mean?\n",
    "2. How many features did the feature extractor produce for each image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will extract the weights and biases of the last layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "weights, bias = last_linear_layer.get_weights()\n",
    "print(\"weights:\", weights.shape)\n",
    "print(\"bias:\", bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observe*: How does the shape of `weights` compare to your answer to the previous question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in class, we can interpret the columns of `weights` as \"prototypes\" for each class. Since we're now working in thousands of dimensions, we can't visualize these prototypes directly. But we can visualize them in terms of what images are aligned with them.\n",
    "\n",
    "Let's start by extracting the prototype for one class. Quick NumPy reference:\n",
    "\n",
    "- Extract a row of an array: `arr[i]`\n",
    "- Extract a column of an array: `arr[:, j]`\n",
    "\n",
    "**Exercise**: Extract the prototype for the \"rose\" class. Check the shape of the resulting array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rose_class_index = ...\n",
    "rose_prototype = ...\n",
    "rose_prototype.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compute how much each image in the validation set aligns with this prototype. We'll do this by computing the dot product between the prototype and the feature vector for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rose_scores = [\n",
    "  feature_vec @ rose_prototype\n",
    "  for feature_vec in val_features\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is actually exactly the same as the dot product of the feature array with the rose prototype vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "rose_scores = val_features @ rose_prototype\n",
    "rose_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use `np.argsort` to find the images that have the highest and lowest scores. We'll identify an image by its *index* in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "images_by_rosiness = np.argsort(rose_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, show the rosiest images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "show_image_grid(\n",
    "  get_images_from_dataset(\n",
    "    val_dataset, images_by_rosiness[::-1][:9]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Show the least rosy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do this for all of the classes. We could loop over all of the classes and do the dot products above...or we could realize that this is **exactly what the matrix multiplication** of the feature array with the weights matrix does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Features matrix shape:\", val_features.shape)\n",
    "print(\"Weights shape:\", weights.shape)\n",
    "\n",
    "# Compute the logits by a forward pass through the linear layer\n",
    "# using the validation features (val_features), weights, and bias\n",
    "logits = ...\n",
    "print(\"Logits shape:\", logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax and Cross-Entropy\n",
    "\n",
    "The last steps in doing by hand what Keras was doing for us are:\n",
    "\n",
    "1. Apply softmax to get the predicted probabilities\n",
    "2. Compute the cross-entropy loss\n",
    "\n",
    "Let's do each of those.\n",
    "\n",
    "First, softmax. For numerical stability, we subtract the maximum value from each row before taking the exponentials. This doesn't change the result -- *think about why*. Then fill in the missing code to compute the softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "logits -= np.max(logits, axis=1, keepdims=True)\n",
    "exp_logits = np.exp(logits)\n",
    "sum_exp_logits = np.sum(exp_logits, axis=1, keepdims=True)\n",
    "val_predicted_probs_manual = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "assert np.allclose(val_predicted_probs, val_predicted_probs_manual, atol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the cross-entropy. To get the negative log of the predicted probability for the correct class, we'll first compute the negative log of *all* of the predicted probabilities, then multiply by the one-hot encoded correct labels. Fill in the missing code to compute the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "logprobs = np.log(val_predicted_probs_manual)\n",
    "print(\"logprobs shape:\", logprobs.shape) # num images by num classes\n",
    "one_hot_labels = keras.utils.to_categorical(val_labels, num_classes=len(class_names)) # num images by num classes\n",
    "\n",
    "loss_per_sample = -np.sum(one_hot_labels * logprobs, axis=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the average of the cross-entropy loss for the entire validation set (using `np.mean`). Does it match the loss that Keras computed for us during training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 | packaged by conda-forge | (main, Jun 14 2022, 07:03:09) [Clang 13.0.1 ]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
